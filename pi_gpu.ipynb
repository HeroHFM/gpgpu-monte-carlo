{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 3: GPGPU Monte Carlo\n",
        "## CSC 490: Lock-free, GPU & vectorization\n",
        "### Victor Kamel"
      ],
      "metadata": {
        "id": "sQOskcM52-yZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Setup\n",
        "\n",
        "(Tested in Google Colab.)\n",
        "\n",
        "> ⚠️ Must select a GPU runtime to run this code. `Runtime > Change runtime type > Hardware accelerator: \"T4 GPU\"`"
      ],
      "metadata": {
        "id": "Y4Twi-BB3Kzw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfjRevD0AFfH",
        "outputId": "7b1d8e48-30af-43b1-9a63-bb17778c006e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-9qpyk03k\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-9qpyk03k\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4293 sha256=0f8a64a849abb13add77c404e03162f65e34a7c03d3a1ba2787f7ac0d4c95898\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dquq184j/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3COXA26NAmJg",
        "outputId": "7f301758-adcf-4fbf-c8ae-03fbd70e943c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Source Code"
      ],
      "metadata": {
        "id": "QWkXd2TZ3bLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name monte_carlo_sim.cu\n",
        "\n",
        "#define _USE_MATH_DEFINES\n",
        "\n",
        "#include <stdlib.h>\n",
        "#include <iostream>\n",
        "#include <utility>\n",
        "#include <chrono>\n",
        "#include <random>\n",
        "#include <cuda.h>\n",
        "#include <thread>\n",
        "#include <vector>\n",
        "#include <math.h>\n",
        "\n",
        "#define CUDA_CALL(exp)                                       \\\n",
        "    do {                                                     \\\n",
        "        cudaError res = (exp);                               \\\n",
        "        if(res != cudaSuccess) {                             \\\n",
        "            printf(\"Error at %s:%d\\n %s\\n\",                  \\\n",
        "                __FILE__,__LINE__, cudaGetErrorString(res)); \\\n",
        "           exit(EXIT_FAILURE);                               \\\n",
        "        }                                                    \\\n",
        "    } while(0)\n",
        "\n",
        "#define CHECK_ERROR(msg)                                             \\\n",
        "    do {                                                             \\\n",
        "        cudaError_t err = cudaGetLastError();                        \\\n",
        "        if(cudaSuccess != err) {                                     \\\n",
        "            printf(\"Error (%s) at %s:%d\\n %s\\n\",                     \\\n",
        "                (msg), __FILE__, __LINE__, cudaGetErrorString(err)); \\\n",
        "            exit(EXIT_FAILURE);                                      \\\n",
        "        }                                                            \\\n",
        "    } while (0)\n",
        "\n",
        "// Tausworth Parameters\n",
        "constexpr unsigned TW_NTHREADS_PER_BLOCK = 1024;\n",
        "constexpr unsigned TW_NBLOCKS            = 64;\n",
        "\n",
        "constexpr unsigned TW_SAMPLES_PER_THREAD = 4096;\n",
        "constexpr unsigned TW_NSEEDS_PER_RNG     = 4;\n",
        "\n",
        "constexpr unsigned TW_NTHREADS = TW_NTHREADS_PER_BLOCK * TW_NBLOCKS;\n",
        "constexpr unsigned TW_NSEEDS   = TW_NTHREADS * TW_NSEEDS_PER_RNG;\n",
        "constexpr unsigned TW_SAMPLES  = TW_SAMPLES_PER_THREAD * TW_NTHREADS;\n",
        "\n",
        "__device__ unsigned d_result;\n",
        "\n",
        "// From GPU Gems 3 Ch. 37 (Lee Howes and David B. Thomas)\n",
        "__device__ unsigned TausStep(unsigned &z, int S1, int S2, int S3, unsigned M)\n",
        "{\n",
        "    unsigned b = (((z << S1) ^ z) >> S2);\n",
        "    return z = (((z & M) << S3) ^ b);\n",
        "}\n",
        "\n",
        "// From GPU Gems 3 Ch. 37 (Lee Howes and David B. Thomas)\n",
        "__device__ unsigned LCGStep(unsigned &z)\n",
        "{\n",
        "    return z = (1664525 * z + 1013904223);\n",
        "}\n",
        "\n",
        "// From GPU Gems 3 Ch. 37 (Lee Howes and David B. Thomas)\n",
        "__device__ float getRandomValueTauswortheUniform(unsigned &z1, unsigned &z2,\n",
        "                                                 unsigned &z3, unsigned &z4)\n",
        "{\n",
        "    unsigned taus = TausStep(z1, 13, 19, 12, 4294967294UL)\n",
        "                    ^ TausStep(z2, 2, 25, 4, 4294967288UL)\n",
        "                    ^ TausStep(z3, 3, 11, 17, 4294967280UL);\n",
        "    unsigned lcg = LCGStep(z4);\n",
        "\n",
        "    return 2.3283064365387e-10f * (taus ^ lcg);\t// taus + lcg\n",
        "}\n",
        "\n",
        "// Block-wise shared memory parallel reduce based on (Meister et al. 2023)\n",
        "template <class T>\n",
        "__device__ void reduceInto(T* loc, T val)\n",
        "{\n",
        "    // Prepare shared memory\n",
        "    __shared__ unsigned smem[TW_NTHREADS_PER_BLOCK];\n",
        "    smem[threadIdx.x] = val;\n",
        "\n",
        "    __syncthreads(); // Synchronize\n",
        "\n",
        "    for (int i = 1; i < blockDim.x; i <<= 1)\n",
        "    {\n",
        "        if (threadIdx.x < (threadIdx.x ^ i))\n",
        "            { smem[threadIdx.x] += smem[threadIdx.x ^ i]; }\n",
        "        __syncthreads(); // Synchronize\n",
        "    }\n",
        "\n",
        "    // Coalesce\n",
        "\tif (threadIdx.x == 0) { atomicAdd(loc, smem[0]); }\n",
        "}\n",
        "\n",
        "__global__ void runSimulation(unsigned *seedPool)\n",
        "{\n",
        "    unsigned z1, z2, z3, z4;\n",
        "    unsigned addr = (blockIdx.x * blockDim.x + threadIdx.x) * TW_NSEEDS_PER_RNG;\n",
        "    z1 = seedPool[addr    ]; z2 = seedPool[addr + 1];\n",
        "    z3 = seedPool[addr + 2]; z4 = seedPool[addr + 3];\n",
        "\n",
        "    // Note: We will not save RNG state for future invocations\n",
        "\n",
        "    float x, y;\n",
        "    unsigned count = 0;\n",
        "    for (unsigned loop = 0; loop < TW_SAMPLES_PER_THREAD; ++loop)\n",
        "    {\n",
        "        x = getRandomValueTauswortheUniform(z1, z2, z3, z4);\n",
        "        y = getRandomValueTauswortheUniform(z1, z2, z3, z4);\n",
        "        count += (x * x) + (y * y) <= 1.0f;\n",
        "    }\n",
        "\n",
        "    reduceInto(&d_result, count);\n",
        "}\n",
        "\n",
        "std::pair<unsigned, unsigned> calculate_samples_gpu()\n",
        "{\n",
        "    // Initialize seed pool (seeds must be at least 128)\n",
        "    unsigned seedPool[TW_NSEEDS];\n",
        "\n",
        "    std::mt19937 gen(std::random_device{}());\n",
        "\n",
        "    for (std::size_t i = 0; i < TW_NSEEDS; ++ i)\n",
        "        do { seedPool[i] = gen(); } while (seedPool[i] < 128);\n",
        "\n",
        "    // CUDA\n",
        "    unsigned *devPool;\n",
        "\n",
        "    CUDA_CALL(cudaMalloc((void **) &devPool, sizeof(unsigned) * TW_NSEEDS));\n",
        "    CUDA_CALL(cudaMemcpy(devPool, seedPool, sizeof(unsigned) * TW_NSEEDS, cudaMemcpyHostToDevice));\n",
        "\n",
        "    // Run simulation\n",
        "    dim3 tw_grid(TW_NBLOCKS, 1, 1);\n",
        "    dim3 tw_threads(TW_NTHREADS_PER_BLOCK, 1, 1);\n",
        "    runSimulation <<< tw_grid, tw_threads >>> (devPool);\n",
        "\n",
        "    CHECK_ERROR(\"Kernel execution failed.\");\n",
        "\n",
        "    typeof(d_result) count;\n",
        "    cudaMemcpyFromSymbol(&count, d_result, sizeof(count), 0, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    CUDA_CALL(cudaFree(devPool));\n",
        "\n",
        "    return std::pair<unsigned, unsigned>(count, TW_SAMPLES);\n",
        "}\n",
        "\n",
        "constexpr unsigned MT_TARGET_SAMPLES = 268435456;\n",
        "\n",
        "std::pair<unsigned, unsigned> calculate_samples_cpu()\n",
        "{\n",
        "    const std::size_t n_threads = std::thread::hardware_concurrency();\n",
        "    const std::size_t samples_per_thread = ceil(MT_TARGET_SAMPLES / n_threads);\n",
        "    const std::size_t n_samples = samples_per_thread * n_threads;\n",
        "\n",
        "    std::vector<std::size_t> samples(n_threads);\n",
        "\n",
        "    {\n",
        "        // Thread \"pool\"\n",
        "        std::vector<std::jthread> spool;\n",
        "        spool.reserve(n_threads);\n",
        "\n",
        "        // Start threads\n",
        "        for (std::size_t n = 0; n < n_threads; ++n) {\n",
        "            spool.emplace_back([&samples, samples_per_thread, n] {\n",
        "                std::random_device rd;\n",
        "                std::mt19937 gen(rd());\n",
        "                std::uniform_real_distribution<float> dist(-1.0f, 1.0f);\n",
        "\n",
        "                std::size_t count = 0;\n",
        "                for (std::size_t i = 0; i < samples_per_thread; ++i) {\n",
        "                    float x = dist(gen);\n",
        "                    float y = dist(gen);\n",
        "                    count += (x * x) + (y * y) <= 1.0f;\n",
        "                }\n",
        "                samples[n] = count;\n",
        "            });\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return std::pair<unsigned, unsigned>(\n",
        "        std::accumulate(samples.cbegin(), samples.cend(), 0),\n",
        "        n_samples\n",
        "    );\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    static_assert(sizeof(unsigned) == 4);\n",
        "\n",
        "#ifdef GPU\n",
        "    std::cout << \"Threads / Block: \" << TW_NTHREADS_PER_BLOCK << std::endl;\n",
        "    std::cout << \"Blocks: \" << TW_NBLOCKS << std::endl;\n",
        "#elif CPU\n",
        "    std::cout << \"Threads: \" << std::thread::hardware_concurrency() << std::endl;\n",
        "#else\n",
        "#error(\"Provide a platform [GPU, CPU].\")\n",
        "#endif\n",
        "\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    auto begin = std::chrono::high_resolution_clock::now();\n",
        "#ifdef GPU\n",
        "    auto [hit, total] = calculate_samples_gpu();\n",
        "#elif CPU\n",
        "    auto [hit, total] = calculate_samples_cpu();\n",
        "#endif\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - begin).count();\n",
        "\n",
        "    float PI = static_cast<float>(4 * hit) / static_cast<float>(total);\n",
        "\n",
        "    std::cout << \"Time (ms): \" << duration << std::endl;\n",
        "    std::cout << \"Samples: \" << total << std::endl;\n",
        "    std::cout << \"PI: \" << PI << std::endl;\n",
        "    std::cout << \"MSE: \" << (PI - M_PI) * (PI - M_PI) << std::endl;\n",
        "\n",
        "    return EXIT_SUCCESS;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2gFLVYonrhGa",
        "outputId": "a7bd3c2b-b788-4aa8-89ce-1c3fff0fcd91"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/monte_carlo_sim.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile and Run (GPU)"
      ],
      "metadata": {
        "id": "CQ-A1VN8OEy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o /content/src/gpu /content/src/monte_carlo_sim.cu -DGPU -std=c++20"
      ],
      "metadata": {
        "id": "69Ynq7y3wRsi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/src/gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNoJPcLWwRuz",
        "outputId": "7262f5fa-a0ad-48e3-cb0d-8cf549ae75d2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threads / Block: 1024\n",
            "Blocks: 64\n",
            "\n",
            "Time (ms): 126\n",
            "Samples: 268435456\n",
            "PI: 3.14157\n",
            "MSE: 4.36535e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compile and Run (CPU)"
      ],
      "metadata": {
        "id": "j_mvnKMwOLTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o /content/src/cpu /content/src/monte_carlo_sim.cu -DCPU -std=c++20"
      ],
      "metadata": {
        "id": "UXVmel8x5agR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/src/cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltyhFbm25aqJ",
        "outputId": "e936e65f-a2af-4232-cf42-805e00de257f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threads: 2\n",
            "\n",
            "Time (ms): 19686\n",
            "Samples: 268435456\n",
            "PI: 3.1414\n",
            "MSE: 3.66197e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Profiling"
      ],
      "metadata": {
        "id": "s7nG541kONSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvprof /content/src/gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqkCj_ayOQso",
        "outputId": "0340a0c1-9320-4616-d191-d4878e28eefc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threads / Block: 1024\n",
            "Blocks: 64\n",
            "\n",
            "==603== NVPROF is profiling process 603, command: /content/src/gpu\n",
            "Time (ms): 425\n",
            "Samples: 268435456\n",
            "PI: 3.14145\n",
            "MSE: 2.13344e-08\n",
            "==603== Profiling application: /content/src/gpu\n",
            "==603== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   98.51%  5.9493ms         1  5.9493ms  5.9493ms  5.9493ms  runSimulation(unsigned int*)\n",
            "                    1.45%  87.646us         1  87.646us  87.646us  87.646us  [CUDA memcpy HtoD]\n",
            "                    0.04%  2.1760us         1  2.1760us  2.1760us  2.1760us  [CUDA memcpy DtoH]\n",
            "      API calls:   50.59%  132.47ms         1  132.47ms  132.47ms  132.47ms  cudaMalloc\n",
            "                   46.91%  122.83ms         1  122.83ms  122.83ms  122.83ms  cudaLaunchKernel\n",
            "                    2.28%  5.9589ms         1  5.9589ms  5.9589ms  5.9589ms  cudaMemcpyFromSymbol\n",
            "                    0.10%  267.66us         1  267.66us  267.66us  267.66us  cudaMemcpy\n",
            "                    0.06%  148.72us         1  148.72us  148.72us  148.72us  cudaFree\n",
            "                    0.05%  142.46us       114  1.2490us     135ns  53.408us  cuDeviceGetAttribute\n",
            "                    0.00%  10.801us         1  10.801us  10.801us  10.801us  cuDeviceGetName\n",
            "                    0.00%  7.5030us         1  7.5030us  7.5030us  7.5030us  cuDeviceGetPCIBusId\n",
            "                    0.00%  3.4630us         1  3.4630us  3.4630us  3.4630us  cuDeviceTotalMem\n",
            "                    0.00%  1.8320us         3     610ns     211ns  1.3680us  cuDeviceGetCount\n",
            "                    0.00%  1.0990us         1  1.0990us  1.0990us  1.0990us  cudaGetLastError\n",
            "                    0.00%  1.0670us         2     533ns     205ns     862ns  cuDeviceGet\n",
            "                    0.00%     704ns         1     704ns     704ns     704ns  cuDeviceGetUuid\n",
            "                    0.00%     524ns         1     524ns     524ns     524ns  cuModuleGetLoadingMode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ncu /content/src/gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJT91ulFOWia",
        "outputId": "549573c3-9e2a-43ce-97d0-3641bce685ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threads / Block: 1024\n",
            "Blocks: 64\n",
            "\n",
            "==PROF== Connected to process 3301 (/content/src/gpu)\n",
            "==PROF== Profiling \"runSimulation(unsigned int *)\" - 0: 0%....50%....100% - 8 passes\n",
            "Time (ms): 959\n",
            "Samples: 268435456\n",
            "PI: 3.14161\n",
            "MSE: 2.35506e-10\n",
            "==PROF== Disconnected from process 3301\n",
            "[3301] gpu@127.0.0.1\n",
            "  runSimulation(unsigned int *) (64, 1, 1)x(1024, 1, 1), Context 1, Stream 7, Device 0, CC 7.5\n",
            "    Section: GPU Speed Of Light Throughput\n",
            "    ----------------------- ------------- ------------\n",
            "    Metric Name               Metric Unit Metric Value\n",
            "    ----------------------- ------------- ------------\n",
            "    DRAM Frequency          cycle/nsecond         5.00\n",
            "    SM Frequency            cycle/usecond       585.19\n",
            "    Elapsed Cycles                  cycle    3,476,367\n",
            "    Memory Throughput                   %         0.11\n",
            "    DRAM Throughput                     %         0.07\n",
            "    Duration                      msecond         5.94\n",
            "    L1/TEX Cache Throughput             %         0.14\n",
            "    L2 Cache Throughput                 %         0.02\n",
            "    SM Active Cycles                cycle 2,780,331.98\n",
            "    Compute (SM) Throughput             %        75.43\n",
            "    ----------------------- ------------- ------------\n",
            "\n",
            "    OPT   Compute is more heavily utilized than Memory: Look at the Compute Workload Analysis section to see what the   \n",
            "          compute pipelines are spending their time doing. Also, consider whether any computation is redundant and      \n",
            "          could be reduced or moved to look-up tables.                                                                  \n",
            "\n",
            "    Section: Launch Statistics\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Metric Name                          Metric Unit    Metric Value\n",
            "    -------------------------------- --------------- ---------------\n",
            "    Block Size                                                 1,024\n",
            "    Function Cache Configuration                     CachePreferNone\n",
            "    Grid Size                                                     64\n",
            "    Registers Per Thread             register/thread              21\n",
            "    Shared Memory Configuration Size           Kbyte           32.77\n",
            "    Driver Shared Memory Per Block        byte/block               0\n",
            "    Dynamic Shared Memory Per Block       byte/block               0\n",
            "    Static Shared Memory Per Block       Kbyte/block            4.10\n",
            "    Threads                                   thread          65,536\n",
            "    Waves Per SM                                                1.60\n",
            "    -------------------------------- --------------- ---------------\n",
            "\n",
            "    OPT   If you execute __syncthreads() to synchronize the threads of a block, it is recommended to have more than the \n",
            "          achieved 1 blocks per multiprocessor. This way, blocks that aren't waiting for __syncthreads() can keep the   \n",
            "          hardware busy.                                                                                                \n",
            "\n",
            "    Section: Occupancy\n",
            "    ------------------------------- ----------- ------------\n",
            "    Metric Name                     Metric Unit Metric Value\n",
            "    ------------------------------- ----------- ------------\n",
            "    Block Limit SM                        block           16\n",
            "    Block Limit Registers                 block            2\n",
            "    Block Limit Shared Mem                block            8\n",
            "    Block Limit Warps                     block            1\n",
            "    Theoretical Active Warps per SM        warp           32\n",
            "    Theoretical Occupancy                     %          100\n",
            "    Achieved Occupancy                        %        99.99\n",
            "    Achieved Active Warps Per SM           warp        32.00\n",
            "    ------------------------------- ----------- ------------\n",
            "\n",
            "    INF   This kernel's theoretical occupancy is not impacted by any block limit.                                       \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X4FObTwW_IH",
        "outputId": "0ce2a7b3-ec3b-4c8c-f947-afd368e00de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec 22 02:30:20 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    }
  ]
}